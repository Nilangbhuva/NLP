# 🔤 Gujarati Text Tokenizer

## 📋 Table of Contents
- [About](#about)
- [Key Features](#key-features)
- [Getting Started](#getting-started)
- [How to Use](#how-to-use)
- [Regular Expression Patterns](#regular-expression-patterns)
- [Development Information](#development-information)

## 📖 About

A comprehensive solution for **tokenizing Gujarati text** into words and sentences using advanced regular expressions. This project addresses the specific challenges of processing Gujarati script, ensuring accurate handling of matras (vowel signs) while intelligently protecting special content such as URLs, email addresses, and abbreviations.

## 🌟 Key Features

### 🔍 **Word Tokenization** (`tokenizer_Regex.py`)
- ✅ **Individual word extraction** from Gujarati text
- ✅ **Matra preservation** - keeps vowel signs attached to base characters
- ✅ **Smart protection** for URLs, emails, and dates
- ✅ **Clean output** - generates `gu_words.txt` with one word per line

### 📝 **Sentence Segmentation** (`sentence_tokenizer_Regex.py`)
- ✅ **Complete sentence detection** with proper boundaries
- ✅ **Gujarati punctuation support** (।, ॥)
- ✅ **Abbreviation protection** prevents false sentence breaks
- ✅ **Fragment merging** for improved sentence quality
- ✅ **Organized output** - creates `gu_sentences.txt` with one sentence per line

## 🚀 Getting Started

### Prerequisites
- Python 3.x (tested with 3.8+)

### Setup Process
1. **Clone the repository**
2. **Verify Python installation**
3. **Install dependencies** (if required):
   ```bash
   pip install regex
   ```

## 💡 How to Use

### Step-by-Step Guide

1. **Prepare your input**: Place Gujarati text in a file (example: `input.txt`)

2. **Execute tokenization**:
   ```bash
   # For word tokenization
   python tokenizer_Regex.py input.txt
   
   # For sentence tokenization
   python sentence_tokenizer_Regex.py input.txt
   ```

3. **Review results**: Check generated output files (`gu_words.txt` or `gu_sentences.txt`)

## 🔧 Regular Expression Patterns

### 📚 **Fundamental Patterns**
| Pattern | Description |
|---------|-------------|
| `\d` | Digit matching |
| `\w` | Word characters (includes Gujarati) |
| `\s` | Whitespace detection |
| `.` | Universal character matcher |
| `|` | Logical OR operator |

### 🎯 **Gujarati-Specific Patterns**
- **Character ranges**: Unicode support for Gujarati characters and matras
- **Abbreviation patterns**: Recognition of common Gujarati abbreviations
- **Punctuation handling**: Sentence-ending marks (।, ॥, ?, !)

### 🛡️ **Protected Content Patterns**
| Content Type | Regex Pattern |
|--------------|---------------|
| **Email addresses** | `[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}` |
| **URLs** | `https?://\S+` |
| **Date formats** | `\d{1,2}\.\d{1,2}\.\d{2,4}` |
| **Abbreviations** | `[અ-હ]\.([અ-હ]\.)+` |

## 🔬 Development Information

### 📁 **Project Structure**
- **Primary tokenizer**: `tokenizer_Regex.py` (stable, production-ready)
- **Experimental version**: `tokenizer_layman.py` (under active development)

### 🔧 **Technical Specifications**
- **Minimum Python version**: 3.8+
- **Testing status**: Thoroughly tested and validated
- **Contribution policy**: Community contributions welcome!

---
*Built with ❤️ for the Gujarati language processing community*