{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48423b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\nilang\\anaconda3\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\nilang\\anaconda3\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-21.0.0-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\nilang\\anaconda3\\lib\\site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\nilang\\anaconda3\\lib\\site-packages (from datasets) (2.1.4)\n",
      "Collecting requests>=2.32.2 (from datasets)\n",
      "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\nilang\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.34.3-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\nilang\\anaconda3\\lib\\site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\nilang\\anaconda3\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\nilang\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.9.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\nilang\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.9.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\nilang\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nilang\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nilang\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nilang\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\nilang\\anaconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nilang\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nilang\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\nilang\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\nilang\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\nilang\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\nilang\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\nilang\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\nilang\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.9.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nilang\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "   ---------------------------------------- 0.0/494.8 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 30.7/494.8 kB 1.3 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 92.2/494.8 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 204.8/494.8 kB 1.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 286.7/494.8 kB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 494.8/494.8 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.34.3-py3-none-any.whl (558 kB)\n",
      "   ---------------------------------------- 0.0/558.8 kB ? eta -:--:--\n",
      "   ----------------------------------- --- 512.0/558.8 kB 15.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 558.8/558.8 kB 6.9 MB/s eta 0:00:00\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "   ---------------------------------------- 0.0/143.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 143.5/143.5 kB 4.3 MB/s eta 0:00:00\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "   ---------------------------------------- 0.0/116.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 116.3/116.3 kB 6.6 MB/s eta 0:00:00\n",
      "Downloading pyarrow-21.0.0-cp311-cp311-win_amd64.whl (26.2 MB)\n",
      "   ---------------------------------------- 0.0/26.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.4/26.2 MB 13.2 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.9/26.2 MB 11.9 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 1.5/26.2 MB 13.9 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 2.2/26.2 MB 13.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 2.7/26.2 MB 12.5 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 3.5/26.2 MB 13.8 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 4.0/26.2 MB 12.9 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 4.7/26.2 MB 13.0 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 5.6/26.2 MB 14.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 6.0/26.2 MB 13.3 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 6.8/26.2 MB 13.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 7.5/26.2 MB 14.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 8.3/26.2 MB 14.3 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 9.2/26.2 MB 14.6 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 9.7/26.2 MB 14.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 10.7/26.2 MB 14.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 11.5/26.2 MB 15.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 12.4/26.2 MB 15.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 13.1/26.2 MB 16.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 14.2/26.2 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 15.1/26.2 MB 17.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 16.3/26.2 MB 18.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 17.4/26.2 MB 19.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 18.4/26.2 MB 19.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 19.7/26.2 MB 21.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 20.5/26.2 MB 21.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 22.0/26.2 MB 24.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 22.8/26.2 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 24.1/26.2 MB 24.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.4/26.2 MB 22.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.2 MB 24.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.2 MB 24.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.2/26.2 MB 21.8 MB/s eta 0:00:00\n",
      "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading xxhash-3.5.0-cp311-cp311-win_amd64.whl (30 kB)\n",
      "Installing collected packages: xxhash, tqdm, requests, pyarrow, dill, multiprocess, huggingface-hub, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.65.0\n",
      "    Uninstalling tqdm-4.65.0:\n",
      "      Successfully uninstalled tqdm-4.65.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 14.0.2\n",
      "    Uninstalling pyarrow-14.0.2:\n",
      "      Successfully uninstalled pyarrow-14.0.2\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.7\n",
      "    Uninstalling dill-0.3.7:\n",
      "      Successfully uninstalled dill-0.3.7\n",
      "Successfully installed datasets-4.0.0 dill-0.3.8 huggingface-hub-0.34.3 multiprocess-0.70.16 pyarrow-21.0.0 requests-2.32.4 tqdm-4.67.1 xxhash-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.75 requires requests_mock, which is not installed.\n",
      "conda-repo-cli 1.0.75 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.75 requires requests==2.31.0, but you have requests 2.32.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f7f0608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cabb79df3df24fcb94d47ecb06bb1366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nilang\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Nilang\\.cache\\huggingface\\hub\\datasets--ai4bharat--IndicCorpV2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "BuilderConfig TextConfig(name='indiccorp_v2', version=0.0.0, data_dir=None, data_files={'asm_Beng': ['data/as.txt'], 'ben_Beng': ['data/bn.txt'], 'brx_Deva': ['data/bd.txt'], 'doi_Deva': ['data/dg.txt'], 'gom_Deva': ['data/gom.txt'], 'guj_Gujr': ['data/gu.txt'], 'hin_Deva': ['data/hi-*.txt'], 'kan_Knda': ['data/kn.txt'], 'kas_Arab': ['data/ks.txt'], 'mai_Deva': ['data/mai.txt'], 'mal_Mlym': ['data/ml.txt'], 'mar_Deva': ['data/mr.txt'], 'mni_Mtei': ['data/mni.txt'], 'npi_Deva': ['data/ne.txt'], 'ory_Orya': ['data/or.txt'], 'pan_Guru': ['data/pa.txt'], 'san_Deva': ['data/sa.txt'], 'snd_Deva': ['data/sd.txt'], 'tam_Taml': ['data/ta.txt'], 'tel_Telu': ['data/te.txt'], 'urd_Arab': ['data/ur.txt'], 'khasi': ['data/kha.txt'], 'santhali': ['data/sat.txt']}, description=None, features=None, encoding='utf-8', encoding_errors=None, chunksize=10485760, keep_linebreaks=False, sample_by='line') doesn't have a 'lang' key.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[1;32m----> 3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mai4bharat/IndicCorpV2\u001b[39m\u001b[38;5;124m\"\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mguj_Gujr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Nilang\\anaconda3\\Lib\\site-packages\\datasets\\load.py:1392\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[0;32m   1387\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[0;32m   1388\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[0;32m   1389\u001b[0m )\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[1;32m-> 1392\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m load_dataset_builder(\n\u001b[0;32m   1393\u001b[0m     path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[0;32m   1394\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   1395\u001b[0m     data_dir\u001b[38;5;241m=\u001b[39mdata_dir,\n\u001b[0;32m   1396\u001b[0m     data_files\u001b[38;5;241m=\u001b[39mdata_files,\n\u001b[0;32m   1397\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m   1398\u001b[0m     features\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[0;32m   1399\u001b[0m     download_config\u001b[38;5;241m=\u001b[39mdownload_config,\n\u001b[0;32m   1400\u001b[0m     download_mode\u001b[38;5;241m=\u001b[39mdownload_mode,\n\u001b[0;32m   1401\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m   1402\u001b[0m     token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m   1403\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_kwargs,\n\u001b[0;32m   1405\u001b[0m )\n\u001b[0;32m   1407\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[0;32m   1408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "File \u001b[1;32mc:\\Users\\Nilang\\anaconda3\\Lib\\site-packages\\datasets\\load.py:1166\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[1;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, **config_kwargs)\u001b[0m\n\u001b[0;32m   1164\u001b[0m builder_cls \u001b[38;5;241m=\u001b[39m get_dataset_builder_class(dataset_module, dataset_name\u001b[38;5;241m=\u001b[39mdataset_name)\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;66;03m# Instantiate the dataset builder\u001b[39;00m\n\u001b[1;32m-> 1166\u001b[0m builder_instance: DatasetBuilder \u001b[38;5;241m=\u001b[39m builder_cls(\n\u001b[0;32m   1167\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m   1168\u001b[0m     dataset_name\u001b[38;5;241m=\u001b[39mdataset_name,\n\u001b[0;32m   1169\u001b[0m     config_name\u001b[38;5;241m=\u001b[39mconfig_name,\n\u001b[0;32m   1170\u001b[0m     data_dir\u001b[38;5;241m=\u001b[39mdata_dir,\n\u001b[0;32m   1171\u001b[0m     data_files\u001b[38;5;241m=\u001b[39mdata_files,\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28mhash\u001b[39m\u001b[38;5;241m=\u001b[39mdataset_module\u001b[38;5;241m.\u001b[39mhash,\n\u001b[0;32m   1173\u001b[0m     info\u001b[38;5;241m=\u001b[39minfo,\n\u001b[0;32m   1174\u001b[0m     features\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[0;32m   1175\u001b[0m     token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m   1176\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   1177\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbuilder_kwargs,\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_kwargs,\n\u001b[0;32m   1179\u001b[0m )\n\u001b[0;32m   1180\u001b[0m builder_instance\u001b[38;5;241m.\u001b[39m_use_legacy_cache_dir_if_possible(dataset_module)\n\u001b[0;32m   1182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m builder_instance\n",
      "File \u001b[1;32mc:\\Users\\Nilang\\anaconda3\\Lib\\site-packages\\datasets\\builder.py:343\u001b[0m, in \u001b[0;36mDatasetBuilder.__init__\u001b[1;34m(self, cache_dir, dataset_name, config_name, hash, base_path, info, features, token, repo_id, data_files, data_dir, storage_options, writer_batch_size, **config_kwargs)\u001b[0m\n\u001b[0;32m    341\u001b[0m     config_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m data_dir\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_kwargs \u001b[38;5;241m=\u001b[39m config_kwargs\n\u001b[1;32m--> 343\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_builder_config(\n\u001b[0;32m    344\u001b[0m     config_name\u001b[38;5;241m=\u001b[39mconfig_name,\n\u001b[0;32m    345\u001b[0m     custom_features\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_kwargs,\n\u001b[0;32m    347\u001b[0m )\n\u001b[0;32m    349\u001b[0m \u001b[38;5;66;03m# prepare info: DatasetInfo are a standardized dataclass across all datasets\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# Prefill datasetinfo\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Nilang\\anaconda3\\Lib\\site-packages\\datasets\\builder.py:560\u001b[0m, in \u001b[0;36mDatasetBuilder._create_builder_config\u001b[1;34m(self, config_name, custom_features, **config_kwargs)\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    559\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(builder_config, key):\n\u001b[1;32m--> 560\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuilderConfig \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbuilder_config\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m key.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    561\u001b[0m             \u001b[38;5;28msetattr\u001b[39m(builder_config, key, value)\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m builder_config\u001b[38;5;241m.\u001b[39mname:\n",
      "\u001b[1;31mValueError\u001b[0m: BuilderConfig TextConfig(name='indiccorp_v2', version=0.0.0, data_dir=None, data_files={'asm_Beng': ['data/as.txt'], 'ben_Beng': ['data/bn.txt'], 'brx_Deva': ['data/bd.txt'], 'doi_Deva': ['data/dg.txt'], 'gom_Deva': ['data/gom.txt'], 'guj_Gujr': ['data/gu.txt'], 'hin_Deva': ['data/hi-*.txt'], 'kan_Knda': ['data/kn.txt'], 'kas_Arab': ['data/ks.txt'], 'mai_Deva': ['data/mai.txt'], 'mal_Mlym': ['data/ml.txt'], 'mar_Deva': ['data/mr.txt'], 'mni_Mtei': ['data/mni.txt'], 'npi_Deva': ['data/ne.txt'], 'ory_Orya': ['data/or.txt'], 'pan_Guru': ['data/pa.txt'], 'san_Deva': ['data/sa.txt'], 'snd_Deva': ['data/sd.txt'], 'tam_Taml': ['data/ta.txt'], 'tel_Telu': ['data/te.txt'], 'urd_Arab': ['data/ur.txt'], 'khasi': ['data/kha.txt'], 'santhali': ['data/sat.txt']}, description=None, features=None, encoding='utf-8', encoding_errors=None, chunksize=10485760, keep_linebreaks=False, sample_by='line') doesn't have a 'lang' key."
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ai4bharat/IndicCorpV2\", lang=\"guj_Gujr\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff486353",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
